{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5f2547",
   "metadata": {},
   "source": [
    "# Face Mask Detection (MLOps Enhanced)\n",
    "\n",
    "This notebook implements Face Mask Detection using **Faster R-CNN**, integrating \"Production-Grade\" practices:\n",
    "- **MLflow**: For experiment tracking (loss, metrics, artifacts).\n",
    "- **Mixed Precision (AMP)**: For faster training and lower memory usage.\n",
    "- **Advanced Evaluation**: Confusion Matrix and Classification Reports adapted for Object Detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e32c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from src.dataset import FaceMaskDataset\n",
    "from src.model import get_model_instance_segmentation\n",
    "import kagglehub\n",
    "import torchvision.transforms as T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0136e61f",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "Downloading and setting up the Face Mask Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5554d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Download and Move\n",
    "try:\n",
    "    cache_path = kagglehub.dataset_download(\"andrewmvd/face-mask-detection\")\n",
    "    target_path = '../data'\n",
    "    \n",
    "    if not os.path.exists(os.path.join(target_path, 'images')):\n",
    "        print(f\"Moving data to {target_path}...\")\n",
    "        os.makedirs(target_path, exist_ok=True)\n",
    "        for item in os.listdir(cache_path):\n",
    "            s = os.path.join(cache_path, item)\n",
    "            d = os.path.join(target_path, item)\n",
    "            if os.path.isdir(s):\n",
    "                if os.path.exists(d): shutil.rmtree(d)\n",
    "                shutil.copytree(s, d)\n",
    "            else:\n",
    "                shutil.copy2(s, d)\n",
    "    ROOT_DIR = target_path\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    ROOT_DIR = '../data'\n",
    "\n",
    "print(f\"Dataset Root: {ROOT_DIR}\")\n",
    "\n",
    "# Transforms\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        # transforms.append(T.RandomHorizontalFlip(0.5)) # Optional augmentation\n",
    "        pass\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "# Load Dataset\n",
    "dataset = FaceMaskDataset(ROOT_DIR, transforms=get_transform(train=False)) # We convert locally in loop if needed, or use separate\n",
    "# Ideally for training we want transforms, but for simplicity we keep it standard\n",
    "dataset_train_full = FaceMaskDataset(ROOT_DIR, transforms=get_transform(train=True))\n",
    "dataset_test_full = FaceMaskDataset(ROOT_DIR, transforms=get_transform(train=False))\n",
    "\n",
    "# Split\n",
    "torch.manual_seed(42)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "test_split = int(0.1 * len(dataset))\n",
    "dataset_train = torch.utils.data.Subset(dataset_train_full, indices[:-test_split])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test_full, indices[-test_split:])\n",
    "\n",
    "# Dataloaders\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "batch_size = 4\n",
    "num_workers = 0 # Windows safe\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=collate_fn)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"Train Size: {len(dataset_train)}, Test Size: {len(dataset_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f579370",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "num_classes = 4 # Background + 3 classes\n",
    "\n",
    "model = get_model_instance_segmentation(num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "scaler = GradScaler() # For Mixed Precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174daff1",
   "metadata": {},
   "source": [
    "## 2. Methodology: Training & Evaluation\n",
    "We adapt the reference notebook methods:\n",
    "- **`train_epoch`**: Uses `tqdm` for progress, `autocast` for AMP, and tracks Loss manually since Detection models return loss dicts.\n",
    "- **`evaluate`**: Since this is Object Detection, we compute metrics by matching predicted boxes to ground truth (IoU >= 0.5) and then calculating classification metrics (Confusion Matrix, Precision, Recall).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5416d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, device, model, optimizer, epoch, total_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{total_epochs}\", unit=\"batch\", leave=True)\n",
    "    \n",
    "    for batch_idx, (images, targets) in enumerate(progress_bar):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed Precision\n",
    "        # Note: Faster R-CNN handles autocast internally mostly, but explicit context is good practice\n",
    "        # However, relying on default behavior for simple scripts:\n",
    "        with autocast(device_type='cuda', enabled=torch.cuda.is_available()):\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        scaler.scale(losses).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        loss_val = losses.item()\n",
    "        total_loss += loss_val\n",
    "        \n",
    "        progress_bar.set_postfix({\"loss\": f\"{loss_val:.4f}\"})\n",
    "        \n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040f9e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_boxes(pred_boxes, true_boxes, iou_threshold=0.5):\n",
    "    # Simple IoU matching\n",
    "    if len(pred_boxes) == 0 or len(true_boxes) == 0:\n",
    "        return []\n",
    "        \n",
    "    ious = torchvision.ops.box_iou(pred_boxes, true_boxes)\n",
    "    matches = []\n",
    "    \n",
    "    # Greedy matching\n",
    "    for i in range(len(pred_boxes)):\n",
    "        best_iou, best_idx = ious[i].max(dim=0)\n",
    "        if best_iou > iou_threshold:\n",
    "            matches.append((i, best_idx.item()))\n",
    "            # mask out to prevent reuse? Simple greedy doesn't need complex mask for basic stats\n",
    "            ious[:, best_idx] = -1 \n",
    "            \n",
    "    return matches\n",
    "\n",
    "def evaluate(dataloader, device, model, epoch, class_names):\n",
    "    model.eval()\n",
    "    all_preds_cls = []\n",
    "    all_true_cls = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            images = list(image.to(device) for image in images)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            for i, output in enumerate(outputs):\n",
    "                target = targets[i]\n",
    "                \n",
    "                true_boxes = target['boxes'].to(device)\n",
    "                true_labels = target['labels'].to(device)\n",
    "                \n",
    "                pred_boxes = output['boxes']\n",
    "                pred_labels = output['labels']\n",
    "                pred_scores = output['scores']\n",
    "                \n",
    "                # Filter low confidence\n",
    "                keep = pred_scores > 0.5\n",
    "                pred_boxes = pred_boxes[keep]\n",
    "                pred_labels = pred_labels[keep]\n",
    "                \n",
    "                matches = match_boxes(pred_boxes, true_boxes)\n",
    "                \n",
    "                matched_pred_indices = set()\n",
    "                matched_true_indices = set()\n",
    "                \n",
    "                for p_idx, t_idx in matches:\n",
    "                    all_preds_cls.append(pred_labels[p_idx].item())\n",
    "                    all_true_cls.append(true_labels[t_idx].item())\n",
    "                    matched_pred_indices.add(p_idx)\n",
    "                    matched_true_indices.add(t_idx)\n",
    "                \n",
    "                # False Negatives (Missed ground truths)\n",
    "                for t_idx in range(len(true_labels)):\n",
    "                    if t_idx not in matched_true_indices:\n",
    "                        all_true_cls.append(true_labels[t_idx].item())\n",
    "                        all_preds_cls.append(0) # 0 is background/missed\n",
    "                        \n",
    "                # False Positives (Spurious detections)\n",
    "                for p_idx in range(len(pred_labels)):\n",
    "                    if p_idx not in matched_pred_indices:\n",
    "                        all_true_cls.append(0) # Background\n",
    "                        all_preds_cls.append(pred_labels[p_idx].item())\n",
    "\n",
    "    # Metrics\n",
    "    # We add 'Background' to class names for display if not present\n",
    "    display_names = ['Background'] + list(class_names.values())\n",
    "    \n",
    "    # Filter labels to be within range\n",
    "    unique_labels = sorted(list(set(all_true_cls) | set(all_preds_cls)))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_true_cls, all_preds_cls, labels=[0, 1, 2, 3])\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=display_names, yticklabels=display_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix (Epoch {epoch+1})')\n",
    "    \n",
    "    cm_path = f\"confusion_matrix_epoch_{epoch+1}.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    mlflow.log_artifact(cm_path)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    report = classification_report(all_true_cls, all_preds_cls, target_names=display_names, output_dict=True)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"val_accuracy\", report['accuracy'], step=epoch)\n",
    "    mlflow.log_metric(\"val_f1_macro\", report['macro avg']['f1-score'], step=epoch)\n",
    "    \n",
    "    return report['accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6051c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Experiment Loop\n",
    "experiment_name = \"FaceMask_FasterRCNN\"\n",
    "try:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "except:\n",
    "    pass\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log params\n",
    "    mlflow.log_param(\"epochs\", num_epochs)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"optimizer\", \"SGD\")\n",
    "    mlflow.log_param(\"lr\", 0.005)\n",
    "    \n",
    "    label_map = {1: \"with_mask\", 2: \"without_mask\", 3: \"incorrect\"}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_loss = train_epoch(train_dataloader, device, model, optimizer, epoch, num_epochs)\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        mlflow.log_metric(\"train_loss\", avg_loss, step=epoch)\n",
    "        print(f\"Epoch {epoch+1} Train Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        val_acc = evaluate(test_dataloader, device, model, epoch, label_map)\n",
    "        print(f\"Epoch {epoch+1} Val Accuracy (Box-Matched): {val_acc:.4f}\")\n",
    "        \n",
    "    # Save Model\n",
    "    if not os.path.exists('../models'):\n",
    "        os.makedirs('../models')\n",
    "    torch.save(model.state_dict(), '../models/model_best.pth')\n",
    "    mlflow.log_artifact('../models/model_best.pth')\n",
    "    \n",
    "print(\"Training Complete. Check MLflow UI.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
